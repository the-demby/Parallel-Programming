# ğŸš€ Optimisation parallÃ¨le du mÃ©canisme d'attention

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du cours de Programmation en parallÃ¨le. Il consiste Ã  optimiser l'opÃ©ration d'attention classique utilisÃ©e dans les architectures Transformer :

$$
\text{Attention}(Q, K, V) = \text{softmax}\left( \frac{Q K^\top}{\sqrt{d_k}} \right) V
$$

Notre objectif a Ã©tÃ© de concevoir, implÃ©menter et comparer plusieurs stratÃ©gies de parallÃ©lisation pour cette opÃ©ration, tout en minimisant le nombre dâ€™expÃ©rimentations grÃ¢ce Ã  une dÃ©marche guidÃ©e par le benchmark.

---

## ğŸ§  Objectifs

* ImplÃ©menter plusieurs versions de l'attention avec diffÃ©rents niveaux dâ€™optimisation (OpenMP, AVX2, blocage mÃ©moire, pipeline fusionnÃ©).
* Mettre en place un benchmark fiable, centralisÃ© et statistiquement stable.
* Comparer les performances (temps et accÃ©lÃ©ration) de chaque version.
* Identifier la meilleure stratÃ©gie de parallÃ©lisation Ã  travers des tests intelligents, et non une grille exhaustive.

---

## ğŸ“‚ Structure du projet

```
Parallel-Programming/
â”‚
â”œâ”€â”€ benchmarks/                # DonnÃ©es de benchmark CSV
â”‚   â””â”€â”€ benchmark_all.csv
â”‚
â”œâ”€â”€ figures/                   # Graphiques de performance
â”‚   â”œâ”€â”€ benchmark_temps.png
â”‚   â””â”€â”€ benchmark_speedup.png
â”‚
â”œâ”€â”€ archives/                  # Anciennes versions de lâ€™implÃ©mentation
â”‚
â”œâ”€â”€ attention_numpy.py         # Version NumPy (v0) de l'attention
â”œâ”€â”€ attention_impl.cpp         # ImplÃ©mentation C++ des versions v1 Ã  v4
â”œâ”€â”€ attention_impl.h           # Interface des fonctions C++ pour Cython
â”œâ”€â”€ attention.pyx              # Wrapper Cython
â”‚
â”œâ”€â”€ setup.py                   # Script de compilation Cython/C++
â”œâ”€â”€ benchmark_attention.py     # Script de benchmark principal
â”œâ”€â”€ plot_benchmark.py          # GÃ©nÃ©ration des graphiques
â”œâ”€â”€ test_attention.py          # Tests unitaires de validation
â””â”€â”€ README.md                  # Ce fichier
```

---

## âš™ï¸ Installation

1. Assurez-vous dâ€™avoir un environnement Python â‰¥ 3.10 avec `numpy`, `cython`, `matplotlib` et `pandas`.
2. Compilez lâ€™extension Cython/C++ :

```bash
python setup.py build_ext --inplace
```

---

## ğŸš¦ Lancer les benchmarks

Le script suivant exÃ©cute toutes les versions (v0 Ã  v4) sur des tailles croissantes :

```bash
python benchmark_attention.py
```

Les rÃ©sultats seront sauvegardÃ©s dans `benchmarks/benchmark_all.csv`.

---

## ğŸ“ˆ GÃ©nÃ©rer les graphiques

Pour crÃ©er les figures Ã  partir des rÃ©sultats du benchmark :

```bash
python plot_benchmark.py
```

Les fichiers suivants seront crÃ©Ã©s :

* `figures/benchmark_temps.png`
* `figures/benchmark_speedup.png`

---

## âœ… Versions implÃ©mentÃ©es

| Version | Description                                 |
| ------- | ------------------------------------------- |
| `v0`    | RÃ©fÃ©rence en NumPy                          |
| `v1`    | C++ + OpenMP (multithread)                  |
| `v2`    | Blocage mÃ©moire (cache blocking)            |
| `v3`    | Vectorisation AVX2/FMA sur QKá·              |
| `v4`    | Pipeline fusionnÃ© AVX2 : QKá· + softmax + PV |

---

## ğŸ” RÃ©sultats

* La version v4 devient la plus rapide Ã  partir de `n = 512`.
* Ã€ `n = 1024`, elle dÃ©passe un facteur de speedup de **Ã—1.9** par rapport Ã  NumPy.
* Lâ€™approche par pipeline fusionnÃ© AVX2 est celle qui prÃ©sente le meilleur rapport complexitÃ©/performance.

Les rÃ©sultats complets sont prÃ©sentÃ©s dans les deux graphiques ci-dessous.

<p align="center">
  <img src="figures/benchmark_temps.png" width="450">
  <br>
  <em>Figure : Temps d'exÃ©cution moyen par version</em>
</p>

<p align="center">
  <img src="figures/benchmark_speedup.png" width="450">
  <br>
  <em>Figure : AccÃ©lÃ©ration (speedup) relative Ã  NumPy</em>
</p>

---

## ğŸ“š Licence

Projet acadÃ©mique rÃ©alisÃ© dans le cadre dâ€™un TP du cours *Programmation en parallÃ¨le*. Aucune redistribution commerciale autorisÃ©e.

---

## âœï¸ Auteurs

* Ã‰tudiant : \[Ismael DEMBELE]
* Encadrant : \[Xavier DUPRE]